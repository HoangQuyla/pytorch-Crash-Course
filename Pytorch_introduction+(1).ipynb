{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch introduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD-gLKRjR3Nt",
        "outputId": "634fc1ab-23a1-4cc6-c8b0-e3b69ba75f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/My Drive/Colab Notebooks/pytorch_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVAQi37VR9WJ",
        "outputId": "fe8b8870-b835-45d0-e1bf-7151df05a02b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/pytorch_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorch is a Python-based machine learning library. There are 2 major features in pytorch.\n",
        "\n",
        "\n",
        "*   It has the ability to efficiently perfomr tensor operations with hardware acceleration (GPU)\n",
        "*  It has the ability to build deep neural network\n",
        "\n",
        "Pytorch is a very popular library. \n"
      ],
      "metadata": {
        "id": "DzDiBRw8SyFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# conda install torch torchvision -c pytorch\n",
        "# Checking that pytorch is working properly\n",
        "import torch\n",
        "x= torch.tensor([3.,4.])"
      ],
      "metadata": {
        "id": "s9DtcMkHTVdn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou-YAX1iTuQt",
        "outputId": "a39372bc-e950-4c71-eeb4-41d8a293f29c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3., 4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That means our pytorch is installed and working properly"
      ],
      "metadata": {
        "id": "rPbEjJFPT0xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform some basic operations such as multiplication\n",
        "x= torch.tensor([3.,4.])\n",
        "y= torch.tensor([5.,6.])"
      ],
      "metadata": {
        "id": "PARzVypYT7vd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x*y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvg6oNvWUJ7q",
        "outputId": "d49c8025-64cd-4214-a2c9-ec32db6688bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([15., 24.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors have a property known as order, which will determine the dimensionality of a tensor. \n",
        "\n",
        "An order one tensor is a tensor with a single dimension  which is equivalent to a vector or a list of numbers.\n",
        "\n",
        "An order 2 tensor with 2 dimensions is the same as a matrix and tensor of order 3 will have 3 dimension."
      ],
      "metadata": {
        "id": "jyd-VKR3UR4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A Neural Network with Pytorch**"
      ],
      "metadata": {
        "id": "CJwDoUouU4ID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import torch\n",
        "from torch.autograd import Variable\n"
      ],
      "metadata": {
        "id": "6Z_SsZZCANhr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "\n",
        "train= pd.read_csv(\"train.csv\")\n",
        "train_labels = train['label'].values"
      ],
      "metadata": {
        "id": "4JwMB2P_U8_X"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(np.reshape(train.values[0][1:],(28,28)), cmap=plt.get_cmap('gray'))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "OOEVZ_bOAPjB",
        "outputId": "2036b382-77f4-4ee5-f34a-bdc39e42af91"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to reshape our input to (1,1,28,28). This is a tensor of 1000 x 1000 images. Each image has 28x28 pixel\n",
        "train = train.drop(\"label\", axis=1).values.reshape(len(train),1,28,28)"
      ],
      "metadata": {
        "id": "BKtiW35cVhMm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training data and lables will be converted into tensor. It will help to feed them into neural network\n",
        "X = torch.Tensor(train.astype(float))\n",
        "y = torch.Tensor(train_labels).long()"
      ],
      "metadata": {
        "id": "2uMVcUMLV2Me"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 2 tensors:\n",
        "\n",
        "\n",
        "*   The float tensor which has 32 bit floating points numbers\n",
        "*   The long tensor which has 64 bit integers\n",
        "\n",
        "\n",
        "The X variable has to be float as it will help Pytorch to compute gradients.\n",
        "\n",
        "The y variable which is our lables has to be integers because we will predict values of 1,2,3, and ..."
      ],
      "metadata": {
        "id": "Y9NLvnhvWOid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Our neural network\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784, 392)  # Our first layer has 784 inputs as the size of each image is 28x28\n",
        "    self.fc2 = nn.Linear(392, 196) # Second layer has 392 units as input\n",
        "    self.fc3 = nn.Linear(196, 98) # Third layer has 192\n",
        "    self.fc4 = nn.Linear(98, 10) # Output is the final layer and it has 10 units. The reason for that is we try to predict whether the image is a digit between 0 and 9\n",
        "    self.dropout = nn.Dropout(p=0.2) # Dropout is a way of regularizing our neural networks to prevent overfitting.\n",
        "  # define the forward pass\n",
        "  def forward(self, x): # The forward function willl define the path our input will take throughout the network\n",
        "    x = x.view(x.shape[0], -1)\n",
        "    x = self.dropout(F.relu(self.fc1(x)))\n",
        "    x = self.dropout(F.relu(self.fc2(x)))\n",
        "    x = self.dropout(F.relu(self.fc3(x)))\n",
        "    x = F.log_softmax(self.fc4(x), dim=1)\n",
        "    # It will take our input x and reshape it for use within the neural netowrk, transform it into a 1-dimensional vector and then pass it through our fullly connected layer\n",
        "    # And then wrap it with ReLu activation function to make it non-linear\n",
        "    # After that, we will wrap it in our dropout which was defined in the init function.\n",
        "    # For the prediction layer we willl use the softmax layer because it will help us to calcualte the loss function much more easier.\n",
        "    return x"
      ],
      "metadata": {
        "id": "UlLQJvJi9QMm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the model parameters\n",
        "model = Classifier()\n",
        "loss_function = nn.NLLLoss()\n",
        "opt = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "t2O-VKkeCsW_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train our network\n",
        "# first we need to create a loop that runs once for each epoch of our training. Here we will run our training loop for 50 epochs. We will first take our input tensor of images\n",
        "# and our ouput tensor of labels and transform them into Pytorch variable\n",
        "\n",
        "# A vraible is a pytorch object that contains a backward() method which we can use to perform\n",
        "for epoch in range(50):\n",
        "  images = Variable(X)\n",
        "  labels = Variable(y)\n",
        "  # Next we will call zero_grad on our optimizer to set our calculated gradients to zero\n",
        "  # Within pytorch, gradients are calculated cumulatively on each back probagation.\n",
        "  # While this is useful in some models, such as when training RNN\n",
        "  # We wish to calcualte the gradients from scractch after each epoch to ensure to reset the gradients to 0 after each pass\n",
        "  opt.zero_grad()\n",
        "  # We will make usage of our model's current state to make predictions on our dataset. This is effectively our forward pass as we then use these prediction to calculate our loss\n",
        "  outputs = model(images)\n",
        "  # Using the outputs and the true labels of our dataset, we calculate the total lkoss of our model using the defined loss function, which is in this case is the negative log likelihood\n",
        "  loss = loss_function(outputs, labels)\n",
        "  loss.backward() # call the backprobagate our loss through the network.\n",
        "  opt.step()# we use step() using our optimizer in order to update our model parameter\n",
        "  # After each epoch is complted , we print the total loss\n",
        "  print ('Epoch [%d/%d] Loss: %.4f' %(epoch+1, 50, loss.data.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1imC575DHxD",
        "outputId": "1ea1751d-087a-43c8-a92e-7b6c1f8e6dd3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/50] Loss: 8.0142\n",
            "Epoch [2/50] Loss: 4.6022\n",
            "Epoch [3/50] Loss: 3.0787\n",
            "Epoch [4/50] Loss: 2.0634\n",
            "Epoch [5/50] Loss: 1.7566\n",
            "Epoch [6/50] Loss: 1.5788\n",
            "Epoch [7/50] Loss: 1.4589\n",
            "Epoch [8/50] Loss: 1.3035\n",
            "Epoch [9/50] Loss: 1.0908\n",
            "Epoch [10/50] Loss: 1.0417\n",
            "Epoch [11/50] Loss: 0.9134\n",
            "Epoch [12/50] Loss: 0.8579\n",
            "Epoch [13/50] Loss: 0.8356\n",
            "Epoch [14/50] Loss: 0.6704\n",
            "Epoch [15/50] Loss: 0.6833\n",
            "Epoch [16/50] Loss: 0.6141\n",
            "Epoch [17/50] Loss: 0.6157\n",
            "Epoch [18/50] Loss: 0.5158\n",
            "Epoch [19/50] Loss: 0.5403\n",
            "Epoch [20/50] Loss: 0.4503\n",
            "Epoch [21/50] Loss: 0.4425\n",
            "Epoch [22/50] Loss: 0.4230\n",
            "Epoch [23/50] Loss: 0.4009\n",
            "Epoch [24/50] Loss: 0.3694\n",
            "Epoch [25/50] Loss: 0.3070\n",
            "Epoch [26/50] Loss: 0.3109\n",
            "Epoch [27/50] Loss: 0.2675\n",
            "Epoch [28/50] Loss: 0.2944\n",
            "Epoch [29/50] Loss: 0.2464\n",
            "Epoch [30/50] Loss: 0.2437\n",
            "Epoch [31/50] Loss: 0.2207\n",
            "Epoch [32/50] Loss: 0.2264\n",
            "Epoch [33/50] Loss: 0.1853\n",
            "Epoch [34/50] Loss: 0.2110\n",
            "Epoch [35/50] Loss: 0.1665\n",
            "Epoch [36/50] Loss: 0.1800\n",
            "Epoch [37/50] Loss: 0.1385\n",
            "Epoch [38/50] Loss: 0.1471\n",
            "Epoch [39/50] Loss: 0.1222\n",
            "Epoch [40/50] Loss: 0.1358\n",
            "Epoch [41/50] Loss: 0.1059\n",
            "Epoch [42/50] Loss: 0.1073\n",
            "Epoch [43/50] Loss: 0.1022\n",
            "Epoch [44/50] Loss: 0.1030\n",
            "Epoch [45/50] Loss: 0.0853\n",
            "Epoch [46/50] Loss: 0.1130\n",
            "Epoch [47/50] Loss: 0.0777\n",
            "Epoch [48/50] Loss: 0.0929\n",
            "Epoch [49/50] Loss: 0.0630\n",
            "Epoch [50/50] Loss: 0.0460\n"
          ]
        }
      ]
    }
  ]
}